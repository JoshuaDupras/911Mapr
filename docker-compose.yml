version: "3.9"

services:
  db:
    ports:
      - "32000:3306"
    build:
      context: ./mysql
    networks:
      - db_net

    volumes:
      - db_data:/var/lib/mysql
    environment:
      MYSQL_DATABASE:
      MYSQL_TABLE:
      MYSQL_ROOT_PASSWORD:
      MYSQL_USER:
      MYSQL_PASSWORD:
      TZ: US/Eastern
    restart: always

  zookeeper:
    container_name: zookeeper
    image: confluentinc/cp-zookeeper:6.2.0
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    networks:
      - kafka_net

  kafka_broker:
    image: confluentinc/cp-kafka:6.2.0
    container_name: kafka_broker
    ports:
    # To learn about configuring Kafka for access across networks see
    # https://www.confluent.io/blog/kafka-client-cannot-connect-to-broker-on-aws-on-docker-etc/
      - "9092:9092"
    depends_on:
      - zookeeper
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_INTERNAL:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092,PLAINTEXT_INTERNAL://kafka_broker:29092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
    networks:
      - kafka_net

  # This "container" is a workaround to pre-create topics
  # source: https://github.com/confluentinc/examples/blob/5.1.1-post/microservices-orders/docker-compose.yml#L182-L215
  kafka_setup:
    image: confluentinc/cp-kafka:6.2.0
    hostname: kafka_setup
    container_name: kafka_setup
    depends_on:
      - zookeeper
      - kafka_broker
    command: "bash -c 'echo Waiting for Kafka to be ready... && \
                       cub kafka-ready -b kafka_broker:9092 1 20 && \
                       kafka-topics --create --if-not-exists --zookeeper zookeeper:2181 --partitions 1 --replication-factor 1 --topic live-incidents'"
    environment:
      # The following settings are listed here only to satisfy the image's requirements.
      # We override the image's `command` anyways, hence this container will not start a broker.
      KAFKA_BROKER_ID: ignored
      KAFKA_ZOOKEEPER_CONNECT: ignored
    networks:
      - kafka_net

  rss_scraper:
    depends_on:
      - db
    networks:
      - db_net
    build:
      context: ./rss_scraper
    restart:
      always
    environment:
      MYSQL_HOST:
      MYSQL_DATABASE:
      MYSQL_TABLE:
      MYSQL_ROOT_PASSWORD:
      MYSQL_USER:
      MYSQL_PASSWORD:

  kafka_producer:
    build:
      context: ./kafka_producer
    depends_on:
      - db
      - zookeeper
      - kafka_broker
      - kafka_setup
    restart:
      always
    networks:
      - db_net
      - kafka_net
    environment:
      MYSQL_HOST:
      MYSQL_DATABASE:
      MYSQL_TABLE:
      MYSQL_ROOT_PASSWORD:
      MYSQL_USER:
      MYSQL_PASSWORD:

  web_app:
    build:
      context: ./web_app
    depends_on:
      - db
      - rss_scraper
      - zookeeper
      - kafka_broker
      - kafka_setup
      - kafka_producer
    ports:
      - "80:5000"
    networks:
      - kafka_net
    restart:
      always

volumes:
  db_data: {}

networks:
  db_net:
    driver: bridge
  kafka_net:
    driver: bridge